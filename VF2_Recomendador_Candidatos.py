# -*- coding: utf-8 -*-
"""recomendador_candidatos_streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16oOUo6ftTxYKlT1-0fWB1RB7z02MTAHK
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import json
import requests
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from deep_translator import GoogleTranslator

# === Constantes ===
TRADUCAO_CACHE = 'cache_traducoes.json'
EMBEDDING_VAGA_CACHE = 'cache_embedding_vagas.json'

# === Links de arquivos externos (substitua pelos seus links reais do Hugging Face) ===
LINKS = {
    "embeddings": "https://huggingface.co/datasets/thiagovgs/meu-projeto-dados/resolve/main/embeddings_candidatos.parquet",
    "applicants": "https://huggingface.co/datasets/thiagovgs/meu-projeto-dados/resolve/main/applicants.json",
    "vagas": "https://huggingface.co/datasets/thiagovgs/meu-projeto-dados/resolve/main/vagas.json",
    "prospects": "https://huggingface.co/datasets/thiagovgs/meu-projeto-dados/resolve/main/prospects.json",
}

# === Fun√ß√µes utilit√°rias ===
def baixar_json_grande_hf(url, caminho_destino):
    r = requests.get(url, stream=True)
    r.raise_for_status()
    with open(caminho_destino, "wb") as f:
        for chunk in r.iter_content(8192):
            if chunk:
                f.write(chunk)
    with open(caminho_destino, "r", encoding="utf-8") as f:
        return json.load(f)

@st.cache_data
def carregar_dados():
    df_embeddings = pd.read_parquet(LINKS["embeddings"])

    df_applicants = pd.read_json(LINKS["applicants"], orient='index')
    df_applicants = df_applicants.reset_index()
    df_applicants = df_applicants.rename(columns={"index": "codigo_candidato"})
    infos_basicas = pd.json_normalize(df_applicants['infos_basicas'])
    informacoes_pessoais = pd.json_normalize(df_applicants['informacoes_pessoais'])
    informacoes_profissionais = pd.json_normalize(df_applicants['informacoes_profissionais'])
    formacao_e_idiomas = pd.json_normalize(df_applicants['formacao_e_idiomas'])
    cargo_atual = pd.json_normalize(df_applicants['cargo_atual'])
    df_cv = df_applicants[['cv_pt', 'cv_en']]
    df_applicants = pd.concat([df_applicants['codigo_candidato'].astype(str), infos_basicas, informacoes_pessoais, informacoes_profissionais, formacao_e_idiomas, cargo_atual, df_cv], axis=1)
    # df_applicants = pd.DataFrame.from_dict(applicants, orient='index').reset_index().rename(columns={"index": "codigo_candidato"})
    # infos_basicas = pd.json_normalize(df_applicants['infos_basicas'])
    # informacoes_pessoais = pd.json_normalize(df_applicants['informacoes_pessoais'])
    # nome_completo = informacoes_pessoais['nome']
    # df_cv = df_applicants[['codigo_candidato', 'cv_pt', 'cv_en']]
    # df_applicants = pd.concat([df_applicants['codigo_candidato'].astype(str), nome_completo, df_cv[['cv_pt', 'cv_en']]], axis=1)
    # df_applicants = df_applicants.rename(columns={"nome": "nome"})

    df_vagas = pd.read_json(LINKS["vagas"], orient='index')
    df_vagas = df_vagas.reset_index()
    df_vagas = df_vagas.rename(columns={"index": "id_vaga"})
    df_info_basicas = pd.json_normalize(df_vagas['informacoes_basicas'])
    df_perfil_vaga = pd.json_normalize(df_vagas['perfil_vaga'])
    df_beneficios = pd.json_normalize(df_vagas['beneficios'])
    df_vagas = pd.concat([df_vagas['id_vaga'].astype(str), df_info_basicas, df_perfil_vaga, df_beneficios], axis=1)

    # vagas = baixar_json_grande_hf(LINKS["vagas"], "vagas.json")
    # df_vagas = pd.DataFrame.from_dict(vagas, orient='index').reset_index().rename(columns={"index": "id_vaga"})
    # info_basicas = pd.json_normalize(df_vagas['informacoes_basicas'])
    # df_vagas = pd.concat([df_vagas['id_vaga'].astype(str), info_basicas], axis=1)

    df_prospects = pd.read_json(LINKS["prospects"], orient='index')
    df_prospects['id_vaga'] = df_prospects.index.astype(str)
    titulo = pd.json_normalize(df_prospects['titulo'])
    modalidade = pd.json_normalize(df_prospects['modalidade'])
    df_prospects = df_prospects.explode('prospects').reset_index(drop=True)
    prospects = pd.json_normalize(df_prospects['prospects'])
    df_prospects = pd.concat([df_prospects.drop(columns=['prospects']).reset_index(drop=True), prospects], axis=1)
    df_prospects = df_prospects.rename(columns={'codigo': 'codigo_candidato'})
    # prospects = baixar_json_grande_hf(LINKS["prospects"], "prospects.json")
    # df_prospects = pd.DataFrame.from_dict(prospects, orient='index')
    # df_prospects['id_vaga'] = df_prospects.index.astype(str)
    # df_prospects = df_prospects.explode('prospects').reset_index(drop=True)
    # prospects_df = pd.json_normalize(df_prospects['prospects'])
    # df_prospects = pd.concat([df_prospects.drop(columns=['prospects']).reset_index(drop=True), prospects_df], axis=1)
    # df_prospects = df_prospects.rename(columns={'codigo': 'codigo_candidato'})

    return df_applicants, df_vagas, df_prospects, df_embeddings

def traduzir_para_portugues(texto_original, id_vaga):
    if os.path.exists(TRADUCAO_CACHE):
        with open(TRADUCAO_CACHE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
    else:
        cache = {}
    if str(id_vaga) in cache:
        return cache[str(id_vaga)]
    traduzido = GoogleTranslator(source='auto', target='pt').translate(texto_original)
    cache[str(id_vaga)] = traduzido
    with open(TRADUCAO_CACHE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=4)
    return traduzido

def obter_embedding_vaga(model, texto_pt, id_vaga):
    if os.path.exists(EMBEDDING_VAGA_CACHE):
        with open(EMBEDDING_VAGA_CACHE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
    else:
        cache = {}
    if str(id_vaga) in cache:
        return np.array(cache[str(id_vaga)])
    embedding = model.encode(texto_pt)
    cache[str(id_vaga)] = embedding.tolist()
    with open(EMBEDDING_VAGA_CACHE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=4)
    return embedding

def recomendar_candidatos(id_vaga, top_n, model, df_applicants, df_vagas, df_embeddings, df_prospects):
    vaga = df_vagas[df_vagas['id_vaga'] == id_vaga].iloc[0]
    descricao = ' '.join([
    str(vaga.get('titulo_vaga', '')),
    str(vaga.get('principais_atividades', '')),
    str(vaga.get('competencia_tecnicas_e_comportamentais', ''))
    ])
    #descricao_en = vaga['descricao']
    descricao_pt = traduzir_para_portugues(descricao, id_vaga)
    embedding_vaga = obter_embedding_vaga(model, descricao_pt, id_vaga)

    df_embeddings['similaridade'] = cosine_similarity([embedding_vaga], np.vstack(df_embeddings['embedding'].to_numpy()))[0]
    df_resultado = df_embeddings.merge(df_applicants[['codigo_candidato', 'nome']], on='codigo_candidato', how='left')
    df_resultado = df_resultado.iloc[:, :-1]

    ja_prospectados = df_prospects[df_prospects['id_vaga'] == id_vaga]['codigo_candidato'].astype(str)
    df_resultado['prospect'] = df_resultado['codigo_candidato'].astype(str).isin(ja_prospectados)

    df_resultado = df_resultado.sort_values(by='similaridade', ascending=False).head(top_n)
    return df_resultado[['codigo_candidato', 'nome', 'similaridade', 'prospect', 'cv_pt']]


# === App Streamlit ===
st.title("üîç Recomendador de Candidatos por Vaga")

try:
    df_applicants, df_vagas, df_prospects, df_embeddings = carregar_dados()
except Exception as e:
    st.error(f"‚ùå Erro ao carregar dados: {e}")
    st.stop()

with st.spinner("Carregando dados..."):
    df_applicants, df_vagas, df_prospects, df_embeddings = carregar_dados()

modelo = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2') #('paraphrase-multilingual-MiniLM-L12-v2')
id_vaga = st.selectbox("Selecione a vaga:", df_vagas['id_vaga'].tolist())
top_n = st.slider("N√∫mero de candidatos recomendados:", 1, 50, 10)

if st.button("Recomendar"):
  try:
    st.info("Gerando recomenda√ß√µes...")
    resultados = recomendar_candidatos(id_vaga, top_n, modelo, df_applicants, df_vagas, df_embeddings, df_prospects)
    st.success(f"{len(resultados)} candidatos recomendados:")
    st.dataframe(resultados, use_container_width=True)

    if st.button("Exportar como Excel"):
        resultados.to_excel("candidatos_recomendados.xlsx", index=False)
        with open("candidatos_recomendados.xlsx", "rb") as f:
            st.download_button("üì• Baixar Excel", f, file_name="candidatos_recomendados.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
  except Exception as e:
      st.error(f"‚ùå Erro ao gerar recomenda√ß√µes: {e}")