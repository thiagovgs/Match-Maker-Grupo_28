# -*- coding: utf-8 -*-
"""recomendador_candidatos_streamlit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16oOUo6ftTxYKlT1-0fWB1RB7z02MTAHK
"""

import streamlit as st
import pandas as pd
import numpy as np
import os
import json
import requests
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from deep_translator import GoogleTranslator

# === Constantes de cache ===
TRADUCAO_CACHE = 'cache_traducoes.json'
EMBEDDING_VAGA_CACHE = 'cache_embedding_vagas.json'

# === Links dos arquivos no Google Drive ===
GOOGLE_DRIVE_FILES = {
    #"embeddings_candidatos.parquet": "1ZEUhKB-u6IOcDSjrymDNnkevjWs1epPE",
    "applicants.json": "1MUHzjuR90yfiUD8CCLm6p5N8kUkdV2nl",
    "vagas.json": "1XYZ71_OgocRqQMe_-S96G0vudW4iNQ-C",
    "prospects.json": "1EFtTpkfzoplQWsGwwy7T1lDbdadwHwcM"
}

def baixar_arquivo_drive(nome_arquivo, file_id):
    if not os.path.exists(nome_arquivo):
        url = f"https://drive.google.com/uc?export=download&id={file_id}"
        r = requests.get(url)
        with open(nome_arquivo, 'wb') as f:
            f.write(r.content)

url = "https://huggingface.co/datasets/thiagovgs/meu-projeto-dados/resolve/main/embeddings_candidatos.parquet"
df_embeddings = pd.read_parquet(url)

# def baixar_arquivo_drive(nome_arquivo, file_id):
#     if not os.path.exists(nome_arquivo):
#         url = f"https://drive.google.com/uc?id={file_id}"
#         gdown.download(url, nome_arquivo, quiet=False)

# === Carregar e preparar dados ===
@st.cache_data
def carregar_dados():
    for nome, file_id in GOOGLE_DRIVE_FILES.items():
        baixar_arquivo_drive(nome, file_id)

    df_applicants = pd.read_json('applicants.json', orient='index').reset_index().rename(columns={"index": "codigo_candidato"})
    infos_basicas = pd.json_normalize(df_applicants['infos_basicas'])
    informacoes_pessoais = pd.json_normalize(df_applicants['informacoes_pessoais'])
    nome_completo = informacoes_pessoais['nome']
    df_cv = df_applicants[['codigo_candidato', 'cv_pt', 'cv_en']]
    df_applicants = pd.concat([df_applicants['codigo_candidato'].astype(str), nome_completo, df_cv[['cv_pt', 'cv_en']]], axis=1)

    df_vagas = pd.read_json('vagas.json', orient='index').reset_index().rename(columns={"index": "id_vaga"})
    info_basicas = pd.json_normalize(df_vagas['informacoes_basicas'])
    df_vagas = pd.concat([df_vagas['id_vaga'].astype(str), info_basicas], axis=1)

    df_prospects = pd.read_json('prospects.json', orient='index')
    df_prospects['id_vaga'] = df_prospects.index.astype(str)
    df_prospects = df_prospects.explode('prospects').reset_index(drop=True)
    prospects = pd.json_normalize(df_prospects['prospects'])
    df_prospects = pd.concat([df_prospects.drop(columns=['prospects']).reset_index(drop=True), prospects], axis=1)
    df_prospects = df_prospects.rename(columns={'codigo': 'codigo_candidato'})

    df_embeddings = pd.read_parquet('embeddings_candidatos.parquet')
    return df_applicants, df_vagas, df_prospects, df_embeddings

def traduzir_para_portugues(texto_original, id_vaga):
    if os.path.exists(TRADUCAO_CACHE):
        with open(TRADUCAO_CACHE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
    else:
        cache = {}
    if str(id_vaga) in cache:
        return cache[str(id_vaga)]
    traduzido = GoogleTranslator(source='auto', target='pt').translate(texto_original)
    cache[str(id_vaga)] = traduzido
    with open(TRADUCAO_CACHE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=4)
    return traduzido

def obter_embedding_vaga(model, texto_pt, id_vaga):
    if os.path.exists(EMBEDDING_VAGA_CACHE):
        with open(EMBEDDING_VAGA_CACHE, 'r', encoding='utf-8') as f:
            cache = json.load(f)
    else:
        cache = {}
    if str(id_vaga) in cache:
        return np.array(cache[str(id_vaga)])
    embedding = model.encode(texto_pt)
    cache[str(id_vaga)] = embedding.tolist()
    with open(EMBEDDING_VAGA_CACHE, 'w', encoding='utf-8') as f:
        json.dump(cache, f, ensure_ascii=False, indent=4)
    return embedding

def recomendar_candidatos(id_vaga, top_n, model, df_applicants, df_vagas, df_embeddings, df_prospects):
    vaga = df_vagas[df_vagas['id_vaga'] == id_vaga].iloc[0]
    descricao_en = vaga['descricao']
    descricao_pt = traduzir_para_portugues(descricao_en, id_vaga)
    embedding_vaga = obter_embedding_vaga(model, descricao_pt, id_vaga)

    candidatos_excluidos = df_prospects[df_prospects['id_vaga'] == id_vaga]['codigo_candidato'].astype(str).unique().tolist()
    df_filtrado = df_embeddings[~df_embeddings['codigo_candidato'].astype(str).isin(candidatos_excluidos)]

    X = np.vstack(df_filtrado['embedding'].to_numpy())
    sims = cosine_similarity([embedding_vaga], X)[0]
    df_filtrado['similaridade'] = sims
    df_resultado = df_filtrado.merge(df_applicants, on='codigo_candidato', how='left')
    df_resultado = df_resultado.sort_values(by='similaridade', ascending=False).head(top_n)
    return df_resultado[['codigo_candidato', 'nome_completo', 'similaridade', 'cv_pt']]

# === App Streamlit ===

st.title("üîç Recomendador de Candidatos por Vaga")

df_applicants, df_vagas, df_prospects, df_embeddings = carregar_dados()
modelo = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

id_vaga_selecionada = st.selectbox("Selecione a vaga:", df_vagas['id_vaga'].tolist())
top_n = st.slider("N√∫mero de candidatos recomendados:", 1, 50, 10)

if st.button("Recomendar"):
    st.info("Gerando recomenda√ß√µes...")
    resultados = recomendar_candidatos(id_vaga_selecionada, top_n, modelo, df_applicants, df_vagas, df_embeddings, df_prospects)
    st.success(f"{len(resultados)} candidatos recomendados:")
    st.dataframe(resultados, use_container_width=True)

    if st.button("Exportar como Excel"):
        resultados.to_excel("candidatos_recomendados.xlsx", index=False)
        with open("candidatos_recomendados.xlsx", "rb") as f:
            st.download_button("üì• Baixar Excel", f, file_name="candidatos_recomendados.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
